{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MSA 2023 Phase 2 - Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'seaborn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/1n/vb7mh6v95w3fmvtrx324by_h0000gn/T/ipykernel_69012/2295823588.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'matplotlib'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'inline'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'seaborn'"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Find all variables and understand them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data\n",
    "df = pd.read_csv('../0. Resources/datasets/credit_risk.csv', encoding = 'utf-8')\n",
    "print('-------------- Data Information -----------------')\n",
    "df.info()\n",
    "print('-------------- Null Data Summary -----------------')\n",
    "print(df.isnull().sum())\n",
    "print('-------------- Data Description -----------------')\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Understanding of Credit Risk Variables**\n",
    "\n",
    "`In data exploration phase, not only we have to exam the data quality, but also we should understand the meaning of each features. That would be very helpful in feature engineering which would base on business instinct and make our model explainable especially in banking aspect.`\n",
    "   - \"checking_status\": Categorical data. The status of checking account.\n",
    "   - \"duration\": Continuous data. The period of loan (month).\n",
    "   - \"credit history\": Categorical data. The credit history of customer.\n",
    "   - \"purpose\": Categorical data. The purpose of loan.\n",
    "   - \"credit_amount\": Continuous data. The amount of credit.\n",
    "   - \"savings_status\": Categorical data. Saving range of customer.\n",
    "   - \"employment\": Categorical data. Employment years range of customer.\n",
    "   - \"installment_commitment\": Continuous data. Period range of installment commitment.\n",
    "   - \"personal_status\": Categorical data. Gender and marriage status of customer.\n",
    "   - \"other_parties\": Categorical data. Other parties like guarantor of customer.\n",
    "   - \"residence_since\": Continuous data. Years of residence of customer.\n",
    "   - \"property_magnitude\" Categorical data. Prove of property of customer.\n",
    "   - \"age\": Continuous data. Age of customer.\n",
    "   - \"other_payment_plans\": Categorical data. Other payment plan can refer to paying off debt.\n",
    "   - \"housing\": Categorical data. The status of housing own or rent by customer.\n",
    "   - \"existing_credits\": Continuous data. The credit rate of customer.\n",
    "   - \"job\": Categorical data. Job type of customer.\n",
    "   - \"num_dependents\": Numerical data. The number of dependents that customer has.\n",
    "   - \"own_telephone\": Boolean data. Customer owns a telephone or not.\n",
    "   - \"foreign_worker\": Boolean data. Customer is a foreigner or not.\n",
    "   - \"class\": Boolean data. Target. Customer label, good or bad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous_col = ['age', 'duration', 'credit_amount']\n",
    "categorical_col = [c for c in df.columns if c != 'class' and c not in continuous_col]\n",
    "\n",
    "all_good_cnt = len(df[df['class'] == 'good'])\n",
    "all_bad_cnt = len(df) - all_good_cnt\n",
    "print(all_good_cnt, all_bad_cnt)\n",
    "\n",
    "for c in categorical_col:\n",
    "    print('-----------------------------------------')\n",
    "    print('Categorical Column Name', c)\n",
    "    possibles = list(set(df[c]))\n",
    "    possibles.sort()\n",
    "    for p in possibles:\n",
    "        cnt = len(df[df[c] == p])\n",
    "        good_cnt = len(df[(df[c] == p) & (df['class'] == 'good')])\n",
    "        bad_cnt = cnt - good_cnt\n",
    "        print(p, 'count: %d'%cnt, 'bad rate: %.4f%%'%(100 - 100 * good_cnt / cnt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Visualise data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the boxplot for each numerical column, check the outlier\n",
    "num_col = [c for c in df.columns[df.dtypes == 'float64']]\n",
    "\n",
    "fig, axs = plt.subplots(9,1,dpi=95, figsize=(7,17))\n",
    "i = 0\n",
    "for col in num_col:\n",
    "    axs[i].boxplot(df[col], vert=False)\n",
    "    axs[i].set_ylabel(col)\n",
    "    i+=1\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There is no missing data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are some outlier in columns duration, credit_amount, and age. While existing_credits and num_dependents also has outlier, it is not necessary to deal with it because its number of possible values is small."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instead of dropping those outlier, we can use the truncate value to replace them.\n",
    "def replace_outlier(_df, _col):\n",
    "    q1, q3 = np.percentile(_df[_col], [25, 75])\n",
    "    iqr = q3 - q1\n",
    "    lower_boundary = q1 - 1.5 * iqr\n",
    "    higher_boundary = q3 + 1.5 * iqr\n",
    "    _df[_col] = _df[_col].apply(lambda x: lower_boundary if x < lower_boundary else x)\n",
    "    _df[_col] = _df[_col].apply(lambda x: higher_boundary if x > higher_boundary else x)\n",
    "    return _df\n",
    "\n",
    "outlier_col = ['duration', 'credit_amount', 'age']\n",
    "\n",
    "for c in outlier_col:\n",
    "    df = replace_outlier(df, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('-------------- Data Description -----------------')\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Identify correlated variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the correlation of numerical variables\n",
    "num_col = [c for c in df.columns[df.dtypes == 'float64']]\n",
    "corr = df[num_col].corr()\n",
    " \n",
    "plt.figure(dpi=130)\n",
    "sns.heatmap(df[num_col].corr(), annot=True, fmt= '.2f')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The correlation between duration and credit_amount is 0.64.描述一下，就是这两个变量有正相关，但并没有很明显，其他变量没有明显的正相关和负相关性。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorize continuous features\n",
    "for c in ['age', 'duration', 'credit_amount']:\n",
    "    df[c] = pd.cut(df[c], 4)\n",
    "    df[c] = df[c].astype('category')\n",
    "    print('-----------------------------------------')\n",
    "    print('Categorical Column Name', c)\n",
    "    possibles = list(set(df[c]))\n",
    "    possibles.sort()\n",
    "    for p in possibles:\n",
    "        cnt = len(df[df[c] == p])\n",
    "        good_cnt = len(df[(df[c] == p) & (df['class'] == 'good')])\n",
    "        bad_cnt = cnt - good_cnt\n",
    "        print(p, 'count: %d'%cnt, 'bad rate: %.4f%%'%(100 - 100 * good_cnt / cnt))\n",
    "        \n",
    "for c in ['residence_since', 'existing_credits', 'num_dependents', 'installment_commitment']:\n",
    "    df[c] = df[c].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this case, our target is to identify the bad cases, then we map the good value to 0, and bad value to 1\n",
    "# Transform target label into 1, 0 boolean value\n",
    "\n",
    "df['class'] = df['class'].apply(lambda x: 0 if x == 'good' else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df)\n",
    "\n",
    "col_dict = {}\n",
    "\n",
    "for c in df.columns:\n",
    "    if '<' in c or '>' in c or '[' in c or ']' in c:\n",
    "        replace_col = c.replace('<=X<', 'to').replace('<', 'less').replace('>=', 'greater').replace('[','').replace(']','').replace(',','to').replace('(', '')\n",
    "        col_dict[c] = replace_col\n",
    "\n",
    "print(col_dict)\n",
    "\n",
    "df.rename(columns = col_dict, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the data frame\n",
    "df.to_csv('../0. Resources/datasets/credit_risk_preprocessed.csv', encoding = 'utf-8', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "c1a2242e7081b4f0929018da2a8cc567af1f3cf95e7af08c98cfb4addbb6241a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
